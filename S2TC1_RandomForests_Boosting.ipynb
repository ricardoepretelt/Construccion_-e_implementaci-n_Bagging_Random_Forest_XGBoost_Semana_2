{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: Construcción e implementación de modelos Bagging, Random Forest y XGBoost\n",
    "\n",
    "En este taller podrán poner en práctica sus conocimientos sobre la construcción e implementación de modelos de Bagging, Random Forest y XGBoost. El taller está constituido por 8 puntos, en los cuales deberan seguir las intrucciones de cada numeral para su desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos predicción precio de automóviles\n",
    "\n",
    "En este taller se usará el conjunto de datos de Car Listings de Kaggle donde cada observación representa el precio de un automóvil teniendo en cuenta distintas variables como año, marca, modelo, entre otras. El objetivo es predecir si el precio del automóvil es alto o no. Para más detalles puede visitar el siguiente enlace: [datos](https://www.kaggle.com/jpayne/852k-used-car-listings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "      <th>HighPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>6480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014</td>\n",
       "      <td>39972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2016</td>\n",
       "      <td>18989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>2014</td>\n",
       "      <td>51330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>2007</td>\n",
       "      <td>116065</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  M_CamryLE  \\\n",
       "7    2014     6480        0           0            0         1          0   \n",
       "11   2014    39972        0           0            0         0          1   \n",
       "167  2016    18989        0           0            0         0          0   \n",
       "225  2014    51330        0           0            0         1          0   \n",
       "270  2007   116065        0           1            0         0          0   \n",
       "\n",
       "     M_CamrySE  M_CamryXLE  HighPrice  \n",
       "7            0           0          1  \n",
       "11           0           0          0  \n",
       "167          1           0          1  \n",
       "225          0           0          0  \n",
       "270          0           0          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importación de librerías\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "# Lectura de la información de archivo .csv\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/dataTrain_carListings.zip')\n",
    "\n",
    "# Preprocesamiento de datos para el taller\n",
    "data = data.loc[data['Model'].str.contains('Camry')].drop(['Make', 'State'], axis=1)\n",
    "data = data.join(pd.get_dummies(data['Model'], prefix='M'))\n",
    "data['HighPrice'] = (data['Price'] > data['Price'].mean()).astype(int)\n",
    "data = data.drop(['Model', 'Price'], axis=1)\n",
    "\n",
    "# Visualización dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y)\n",
    "y = data['HighPrice']\n",
    "X = data.drop(['HighPrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de datos en set de entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1 - Árbol de decisión manual\n",
    "\n",
    "En la celda 1 creen un árbol de decisión **manualmente**  que considere los set de entrenamiento y test definidos anteriormente y presenten el acurracy del modelo en el set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy del árbol de decision:  0.8778868360277137\n"
     ]
    }
   ],
   "source": [
    "# Celda 1\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Definición de parámetros y criterios de parada\n",
    "max_depth = None\n",
    "num_pct = 10\n",
    "max_features = None\n",
    "min_gain=0.001\n",
    "\n",
    "# Definición de la función que calcula el gini index\n",
    "def gini(y):\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - (y.mean()**2 + (1 - y.mean())**2)\n",
    "\n",
    "# Definición de la función gini_imputiry para calular la ganancia de una variable predictora j\n",
    "#dado el punto de corte k\n",
    "def gini_impurity(X_col, y, split):\n",
    "    \n",
    "    filter_l = X_col < split\n",
    "    y_l = y.loc[filter_l]\n",
    "    y_r = y.loc[~filter_l]\n",
    "    \n",
    "    n_l = y_l.shape[0]\n",
    "    n_r = y_r.shape[0]\n",
    "    \n",
    "    gini_y = gini(y)\n",
    "    gini_l = gini(y_l)\n",
    "    gini_r = gini(y_r)\n",
    "    \n",
    "    gini_impurity_ = gini_y - (n_l / (n_l + n_r) * gini_l + n_r / (n_l + n_r) * gini_r)\n",
    "    \n",
    "    return gini_impurity_\n",
    "\n",
    "# Definición de la función best_split para calcular cuál es la mejor variable y punto de cortepara hacer la bifurcación del árbol\n",
    "def best_split(X, y, num_pct=10):\n",
    "    \n",
    "    features = range(X.shape[1])\n",
    "    \n",
    "    best_split = [0, 0, 0]  # j, split, gain\n",
    "    \n",
    "    # Para todas las varibles \n",
    "    for j in features:\n",
    "        \n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        # Para cada partición\n",
    "        for split in splits:\n",
    "            gain = gini_impurity(X.iloc[:, j], y, split)\n",
    "                        \n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "    \n",
    "    return best_split\n",
    "\n",
    "\n",
    "# Definición de la función tree_grow para hacer un crecimiento recursivo del árbol\n",
    "def tree_grow(X, y, level=0, min_gain=0.001, max_depth=None, num_pct=10):\n",
    "    \n",
    "    # Si solo es una observación\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calcular la mejor división\n",
    "    j, split, gain = best_split(X, y, num_pct)\n",
    "    \n",
    "    # Guardar el árbol y estimar la predicción\n",
    "    y_pred = int(y.mean() >= 0.5) \n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)  # Corrección Laplace \n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=gain)\n",
    "    # Revisar el criterio de parada \n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # Continuar creando la partición\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "\n",
    "    # Siguiente iteración para cada partición\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "tree = tree_grow(X_train, y_train, level=0, min_gain=0.001, max_depth=3, num_pct=10)\n",
    "\n",
    "# Definición de la función tree_predict para hacer predicciones según las variables 'X' y el árbol 'tree' \n",
    "def tree_predict(X, tree, proba=False):\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "\n",
    "    # Revisar si es el nodo final\n",
    "    if tree['split'] == -1:\n",
    "        if not proba:\n",
    "            predicted = predicted * tree['y_pred']\n",
    "        else:\n",
    "            predicted = predicted * tree['y_prob']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] == 0:  # Si el nodo izquierdo está vacio solo continua con el derecho \n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "        elif X_r.shape[0] == 0:  #  Si el nodo derecho está vacio solo continua con el izquierdo\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "\n",
    "    return predicted\n",
    "\n",
    "y_predicted=tree_predict(X_test, tree)\n",
    "\n",
    "# Calculo de accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_1=accuracy_score(y_test, y_predicted)\n",
    "print('accuracy del árbol de decision: ', accuracy_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2 - Bagging manual\n",
    "\n",
    "En la celda 2 creen un modelo bagging **manualmente** con 10 árboles de clasificación y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arreglo: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Muestreo aleatorio:  [ 6 12 13  9 10 12  6 16  1 17  2 13  8 14  7 19  6 19 12 11]\n"
     ]
    }
   ],
   "source": [
    "# Celda 2\n",
    "\n",
    "# Se crea un arreglo de 1 a 20\n",
    "np.random.seed(1)\n",
    "# Impresión de arreglo y muestreo aleatorio\n",
    "nums = np.arange(1, 21)\n",
    "print('Arreglo:', nums)\n",
    "print('Muestreo aleatorio: ', np.random.choice(a=nums, size=20, replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([3582, 3454, 1346, ...,  826,  801, 5657]),\n",
       " array([6962, 3408, 2553, ..., 6611,  877, 6412]),\n",
       " array([1917, 3131,  384, ..., 2876, 6449, 6557]),\n",
       " array([3849, 4565, 6820, ..., 6835, 4643,  639]),\n",
       " array([2468, 3608, 1367, ..., 3108, 2961, 4357]),\n",
       " array([3142, 1537, 5966, ..., 3224, 6922, 3396]),\n",
       " array([6588, 3753, 1786, ..., 2131, 4627, 5672]),\n",
       " array([1289, 3776,  981, ..., 1891, 6034, 6165]),\n",
       " array([6079, 3819, 6976, ..., 6478, 2225, 5072]),\n",
       " array([3952, 3276,  896, ..., 4589, 1964,  893])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creación de 10 muestras de bootstrap \n",
    "np.random.seed(123)\n",
    "n_samples = X_train.shape[0]\n",
    "n_B = 10\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151599</th>\n",
       "      <td>2016</td>\n",
       "      <td>40999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171999</th>\n",
       "      <td>2014</td>\n",
       "      <td>52527</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304172</th>\n",
       "      <td>2009</td>\n",
       "      <td>123202</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74828</th>\n",
       "      <td>2015</td>\n",
       "      <td>38807</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192974</th>\n",
       "      <td>2005</td>\n",
       "      <td>51260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134843</th>\n",
       "      <td>2014</td>\n",
       "      <td>22221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325075</th>\n",
       "      <td>2013</td>\n",
       "      <td>86593</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61213</th>\n",
       "      <td>2014</td>\n",
       "      <td>28044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181222</th>\n",
       "      <td>2016</td>\n",
       "      <td>49368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275601</th>\n",
       "      <td>2015</td>\n",
       "      <td>32069</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7031 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  M_CamryLE  \\\n",
       "151599  2016    40999        0           0            0         0          0   \n",
       "171999  2014    52527        0           0            0         0          0   \n",
       "304172  2009   123202        0           1            0         0          0   \n",
       "74828   2015    38807        0           0            0         0          0   \n",
       "192974  2005    51260        0           0            0         0          0   \n",
       "...      ...      ...      ...         ...          ...       ...        ...   \n",
       "134843  2014    22221        0           0            0         0          1   \n",
       "325075  2013    86593        0           0            0         0          0   \n",
       "61213   2014    28044        0           0            0         0          0   \n",
       "181222  2016    49368        0           0            0         0          0   \n",
       "275601  2015    32069        1           0            0         0          0   \n",
       "\n",
       "        M_CamrySE  M_CamryXLE  \n",
       "151599          1           0  \n",
       "171999          1           0  \n",
       "304172          0           0  \n",
       "74828           1           0  \n",
       "192974          0           1  \n",
       "...           ...         ...  \n",
       "134843          0           0  \n",
       "325075          1           0  \n",
       "61213           1           0  \n",
       "181222          0           1  \n",
       "275601          0           0  \n",
       "\n",
       "[7031 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualización muestra boostrap #1 para entremiento\n",
    "X_train.iloc[samples[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257343</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326011</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242354</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266376</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396954</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144298</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364521</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120072</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99878</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387162</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3464 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1  2  3  4  5  6  7  8  9\n",
       "257343  0  0  0  0  0  0  0  0  0  0\n",
       "326011  0  0  0  0  0  0  0  0  0  0\n",
       "242354  1  1  1  1  1  1  1  1  1  1\n",
       "266376  1  1  1  1  1  1  1  1  1  1\n",
       "396954  1  1  1  1  1  1  1  1  1  1\n",
       "...    .. .. .. .. .. .. .. .. .. ..\n",
       "144298  1  0  1  1  0  0  1  1  1  1\n",
       "364521  1  1  1  1  1  1  1  1  1  1\n",
       "120072  1  1  1  1  1  1  1  1  1  1\n",
       "99878   0  0  0  0  0  0  0  0  0  0\n",
       "387162  0  0  0  0  0  0  0  0  0  0\n",
       "\n",
       "[3464 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construcción un árbol de decisión para cada muestra boostrap\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Definición del modelo usando sklearn\n",
    "clf = DecisionTreeClassifier(max_depth=None, random_state=123)\n",
    "\n",
    "# DataFrame para guardar las predicciones de cada árbol\n",
    "y_pred = pd.DataFrame(index=y_test.index, columns=[list(range(n_B))])\n",
    "\n",
    "# Entrenamiento de un árbol sobre cada muestra boostrap y predicción sobre los datos de test\n",
    "for i, sample in enumerate(samples):\n",
    "    X_train_2 = X_train.iloc[sample]\n",
    "    y_train_2 = y_train.iloc[sample]\n",
    "    clf.fit(X_train_2, y_train_2)\n",
    "    y_pred.iloc[:,i] = clf.predict(X_test)\n",
    "    \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257343    0.0\n",
       "326011    0.0\n",
       "242354    1.0\n",
       "266376    1.0\n",
       "396954    1.0\n",
       "         ... \n",
       "144298    1.0\n",
       "364521    1.0\n",
       "120072    1.0\n",
       "99878     0.0\n",
       "387162    0.0\n",
       "Name: 0, Length: 3464, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_mode=y_pred.mode(axis=1)[0]\n",
    "y_pred_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy de bagging manual:  0.8507505773672055\n"
     ]
    }
   ],
   "source": [
    "# Calculo de accuracy\n",
    "accuracy_2=accuracy_score(y_test, y_pred_mode)\n",
    "print('accuracy de bagging manual: ', accuracy_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El accuracy obtenido usando bagging manual es satisfactorio, pero es un resultado menor comparado con el decision tree manual. Esto pudo pasar por la aletoriedad. También se observa que no hay muchos cambios entre los distintos\n",
    "árboles del bagging. Todos tienen un error similar de 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 3 - Bagging con librería\n",
    "\n",
    "En la celda 3, con la librería sklearn, entrenen un modelo bagging con 10 árboles de clasificación y el parámetro `max_features` igual a `log(n_features)`. Presenten el acurracy del modelo en el set de test y comenten sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy de bagging con librería:  0.8493071593533488\n"
     ]
    }
   ],
   "source": [
    "# Celda 3\n",
    "\n",
    "# Uso de BaggingRegressor de la libreria (sklearn) donde se usa el modelo DecisionTreeRegressor como estimador\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "n_features=X_train.shape[1]\n",
    "bagclf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=10, max_features=int(np.log(n_features)), \n",
    "                          bootstrap=True, oob_score=True, random_state=1)\n",
    "bagclf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bagclf.predict(X_test)\n",
    "\n",
    "accuracy_3=accuracy_score(y_test, y_pred)\n",
    "print('accuracy de bagging con librería: ', accuracy_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtuvo un resultado satisfactorio, sólo hubo una diferencia mínima comparada con el bagging manual que se puede deber a la aletoriedad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 4 - Random forest con librería\n",
    "\n",
    "En la celda 4, usando la librería sklearn entrenen un modelo de Randon Forest para clasificación y presenten el acurracy del modelo en el set de test y comenten sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=7, n_jobs=-1, random_state=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 4\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Definición de modelo Random Forest para un problema de clasificación\n",
    "clf1 = RandomForestClassifier(n_estimators=7, random_state=1, n_jobs=-1)\n",
    "clf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy de random forest con libreria:  0.8432448036951501\n"
     ]
    }
   ],
   "source": [
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_4=accuracy_score(y_test, y_pred)\n",
    "print('accuracy de random forest con libreria: ', accuracy_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El accuracy con random forest mostró una mejoría comparada con los resultados de bagging y del árbol de decisión.\n",
    "Tiene mucho sentido ya que random forest es un modelo con mejor desempeño pero menos interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 5 - Calibración de parámetros Random forest\n",
    "\n",
    "En la celda 5, calibren los parámetros max_depth, max_features y n_estimators del modelo de Randon Forest para clasificación. Presenten el acurracy del modelo en el set de test, comenten sus resultados y análicen cómo cada parámetro afecta el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid=[{'max_depth': [3, 4, 5, 6],\n",
       "                          'max_features': [6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
       "                          'n_estimators': [6, 7, 8, 9, 10, 11, 12, 13, 14,\n",
       "                                           15]}],\n",
       "             return_train_score=True, scoring='accuracy')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 5\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "{'n_estimators': [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 'max_features': [6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    " 'max_depth': [3,4,5,6]}\n",
    "]\n",
    "clf2 = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(clf2, param_grid, cv=5,\n",
    "scoring='accuracy',\n",
    "return_train_score=True)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'max_features': 8, 'n_estimators': 11}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy de random forest con calibración:  0.8868360277136259\n"
     ]
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier(n_estimators=15, max_depth=6, max_features=6, random_state=1, n_jobs=-1)\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "y_pred = clf2.predict(X_test)\n",
    "accuracy_5=accuracy_score(y_test, y_pred)\n",
    "print('accuracy de random forest con calibración: ', accuracy_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M_CamryBase</td>\n",
       "      <td>0.000256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M_CamryL</td>\n",
       "      <td>0.002045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M_Camry</td>\n",
       "      <td>0.007061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M_CamrySE</td>\n",
       "      <td>0.010258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M_CamryXLE</td>\n",
       "      <td>0.010320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M_CamryLE</td>\n",
       "      <td>0.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M_Camry4dr</td>\n",
       "      <td>0.072563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Year</td>\n",
       "      <td>0.366145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mileage</td>\n",
       "      <td>0.517754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "4  M_CamryBase    0.000256\n",
       "5     M_CamryL    0.002045\n",
       "2      M_Camry    0.007061\n",
       "7    M_CamrySE    0.010258\n",
       "8   M_CamryXLE    0.010320\n",
       "6    M_CamryLE    0.013600\n",
       "3   M_Camry4dr    0.072563\n",
       "0         Year    0.366145\n",
       "1      Mileage    0.517754"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impresión de resultados de desemepeño del modelo\n",
    "feature_cols = X_train.columns[X_train.columns.str.startswith('C') == False]\n",
    "pd.DataFrame({'feature':feature_cols, 'importance':clf2.feature_importances_}).sort_values('importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al hacer la calibración se mejora el desempeño previamente obtenido con random forest e hiperparametros predeterminados. Aumentar el número de estimadores mejora el accuracy y se encuentra un punto óptimo en 11. max_depth y max_features son estables en 6.\n",
    "\n",
    "Revisando las features, se observa que Mileage y year son las variables más importantes, y después se encuentran las variables relacionadas con el modelo del auto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 6 - XGBoost con librería\n",
    "\n",
    "En la celda 6 implementen un modelo XGBoost de clasificación con la librería sklearn, presenten el acurracy del modelo en el set de test y comenten sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "              validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 6\n",
    "from xgboost import XGBClassifier\n",
    "clf3 = XGBClassifier()\n",
    "clf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy de xgboost:  0.8856812933025404\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento (fit) y desempeño del modelo XGBClassifier\n",
    "clf3.fit(X_train, y_train)\n",
    "y_pred = clf3.predict(X_test)\n",
    "\n",
    "accuracy_6=accuracy_score(y_test, y_pred)\n",
    "print('accuracy de xgboost: ', accuracy_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost muestra mejores resultados con valores predeterminados que random forest sin calibración, por lo que seguramente XGBoost es el mejor modelo para este caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 7 - Calibración de parámetros XGBoost\n",
    "\n",
    "En la celda 7 calibren los parámetros learning rate, gamma y colsample_bytree del modelo XGBoost para clasificación. Presenten el acurracy del modelo en el set de test, comenten sus resultados y análicen cómo cada parámetro afecta el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs...\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             param_grid=[{'colsample_bytree': [1, 2, 3, 4, 5],\n",
       "                          'gamma': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 2, 3, 4],\n",
       "                          'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35,\n",
       "                                            0.4, 0.45, 0.5, 0.55, 0.6]}],\n",
       "             return_train_score=True, scoring='accuracy')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 7\n",
    "\n",
    "param_grid = [\n",
    "{'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6],\n",
    " 'gamma': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 2, 3, 4],\n",
    " 'colsample_bytree': [1,2,3,4,5]}\n",
    "]\n",
    "clf4 = XGBClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(clf4, param_grid, cv=5,\n",
    "scoring='accuracy',\n",
    "return_train_score=True)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 1, 'gamma': 4, 'learning_rate': 0.15}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy de xgboost con calibración:  0.8882794457274826\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento (fit) y desempeño del modelo XGBClassifier\n",
    "clf4 = XGBClassifier(colsample_bytree= 1, gamma= 4, learning_rate= 0.15)\n",
    "clf4.fit(X_train, y_train)\n",
    "y_pred = clf4.predict(X_test)\n",
    "\n",
    "accuracy_7=accuracy_score(y_test, y_pred)\n",
    "print('accuracy de xgboost con calibración: ', accuracy_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGboost con calibración muestra los mejores resultados de accuracy comparado con los otros modelos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 8 - Comparación y análisis de resultados\n",
    "En la celda 8 comparen los resultados obtenidos de los diferentes modelos (random forest y XGBoost) y comenten las ventajas del mejor modelo y las desventajas del modelo con el menor desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 8\n",
    "\n",
    "accuracy_1 = round(accuracy_1, 3)\n",
    "accuracy_2 = round(accuracy_2, 3)\n",
    "accuracy_3 = round(accuracy_3, 3)\n",
    "accuracy_4 = round(accuracy_4, 3)\n",
    "accuracy_5 = round(accuracy_5, 3)\n",
    "accuracy_6 = round(accuracy_6, 3)\n",
    "accuracy_7 = round(accuracy_7, 3)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.set_title('Comparación de modelos')\n",
    "ejeX = ['Manual DecisionTree', 'Manual Bagging', 'Bagging libreria', 'RandomForest libreria',\n",
    "        'RandomForest calibrado', 'XGboost con libreria', 'XGboost calibrado']\n",
    "ejeY = [accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5, accuracy_6, accuracy_7]\n",
    "ax.bar(ejeX, ejeY)\n",
    "plt.xticks(rotation=45)\n",
    "def addlabels(x, y, plotP):\n",
    "    for i in range(len(x)):\n",
    "        plotP.text(i, y[i], y[i])\n",
    "addlabels(ejeX, ejeY, plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que en general los resultados de todos los modelos son muy homogéneos. Definitivamente el uso de librerias mejora los resultados con RandomForest y XGboost, por otro lado la calibración mejora aún más el accuracy. Finalmente XGBoost con calibración presenta el mejor resultado, por lo que sería el modelo elegido."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
